{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acceptable-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Today we are going to be looking at decision trees. The way they work is by literally assembling a decision tree, \n",
    "where they learn what questions they should ask that will help accurately determine whether a data point is X, y, z. \n",
    "One question will lead to another and on and on ... until it stops. If you are curious we use CART algorithm for training\n",
    "such decision trees in sealion.They are extremely powerful, sometimes too much. Today we are going to \n",
    "applying them to the titanic dataset, where we will predict whether or not somebody would survive or die. \n",
    "This how advanced machine learning has become. \n",
    "\"\"\"\n",
    "\n",
    "# first let's import sealion and get what we need\n",
    "import sealion as sl \n",
    "from sealion.decision_trees import DecisionTree\n",
    "import pandas as pd # we need this for reading in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-personal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we can load in the dataset\n",
    "titanic_dataframe = pd.read_csv(\"titanic_dataset.csv\") # of my local computer\n",
    "titanic_dataframe # print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proud-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like it has 891 rows and 12 columns. First we can delete some of the features we know we won't use. \n",
    "titanic_dataframe = titanic_dataframe.drop(['Name', 'Ticket', 'Cabin'], axis = 1) # non-numeric\n",
    "titanic_dataframe = titanic_dataframe.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "backed-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0              1         0       3   0  22.0      1      0   7.2500        0\n",
       "1              2         1       1   1  38.0      1      0  71.2833        1\n",
       "2              3         1       3   1  26.0      0      0   7.9250        0\n",
       "3              4         1       1   1  35.0      1      0  53.1000        0\n",
       "4              5         0       3   0  35.0      0      0   8.0500        0\n",
       "..           ...       ...     ...  ..   ...    ...    ...      ...      ...\n",
       "886          887         0       2   0  27.0      0      0  13.0000        0\n",
       "887          888         1       1   1  19.0      0      0  30.0000        0\n",
       "888          889         0       3   1   0.0      1      2  23.4500        0\n",
       "889          890         1       1   0  26.0      0      0  30.0000        1\n",
       "890          891         0       3   0  32.0      0      0   7.7500        2\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we can change the sex column. Female will be 0 and Male will be 1. \n",
    "import numpy as np # we'll need this too\n",
    "sex_col = np.array(titanic_dataframe['Sex'])\n",
    "sex_col[np.where(sex_col == \"male\")] = 0\n",
    "sex_col[np.where(sex_col == \"female\")] = 1\n",
    "titanic_dataframe[\"Sex\"]  = sex_col\n",
    "\n",
    "# we can also change the embarked column - we will make it one-hot-encoded\n",
    "from sealion.utils import one_hot\n",
    "embarked_col = np.array(titanic_dataframe[\"Embarked\"])\n",
    "embarked_col[np.where(embarked_col == \"S\")] = 0\n",
    "embarked_col[np.where(embarked_col == \"C\")] = 1\n",
    "embarked_col[np.where(embarked_col == \"Q\")] = 2 \n",
    "titanic_dataframe[\"Embarked\"] = embarked_col\n",
    "titanic_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lonely-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like we are all set. Time to get the labels and the training and testing data\n",
    "y = np.array(titanic_dataframe['Survived'])\n",
    "titanic_dataframe = titanic_dataframe.drop('Survived', axis = 1)\n",
    "X = np.array(titanic_dataframe)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "anonymous-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll need to one_hot_encode the last column of X_train and X_test (Embarked)\n",
    "embarked_train = one_hot(X_train[:, -1], depth = 3)\n",
    "embarked_test = one_hot(X_test[:, -1], depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "located-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll have to use a bit of the long route to avoid typical rules of numpy\n",
    "new_X_train, new_X_test = [], []\n",
    "X_train, X_test = np.array(X_train).tolist(), np.array(X_test).tolist() # turn them into regular python lists\n",
    "for row in range(len(X_train)) : \n",
    "    observation = X_train[row] # get the row\n",
    "    observation[-1] = embarked_train[row].tolist() # .tolist() helps make sure it can be interpreted (only needed as of v3.0.8 if you are using one_hot_encoded data) \n",
    "    new_X_train.append(observation)\n",
    "    \n",
    "for row in range(len(X_test)) : \n",
    "    observation = X_test[row] # get the row\n",
    "    observation[-1] = embarked_test[row].tolist()\n",
    "    new_X_test.append(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "relative-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = new_X_train, new_X_test # just change the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "starting-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally we can start using the decision trees algorithm!\n",
    "dt = DecisionTree()\n",
    "dt.fit(X_train, y_train) # note that the DecisionTree class is only for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "governing-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy :  1.0\n",
      "Testing accuracy :  0.7686567164179104\n"
     ]
    }
   ],
   "source": [
    "#we'll let's see how it did\n",
    "def evaluate(dt, X_train, y_train, X_test, y_test) : \n",
    "    print(\"Training accuracy : \", dt.evaluate(X_train, y_train))\n",
    "    print(\"Testing accuracy : \", dt.evaluate(X_test, y_test))\n",
    "\n",
    "evaluate(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "weighted-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# woah that's some big overfitting. \n",
    "# because decision trees can go as deep as they want (meaning they can ask and ask questions), they can \n",
    "# almost always find a sequence of questions that are hyperspecific to the training data to get every data point right\n",
    "# as you can see here, all training data was classified correctly, but only 3/4 of all testing data...\n",
    "\n",
    "# luckily there are regularization techniques!\n",
    "# the first is max_branches. A decision tree is really just what it sounds like - a bunch of questions in a tree fashion \n",
    "# to make a decision about whether a data point is X, y, z. If the tree is making 500 trees instead of 50 to \n",
    "# just get a few points in the training data correct, maybe we should stop that and end at the generalizing 50. \n",
    "\n",
    "# but before we do that we need to know how many trees their actually are. Luckily we have a good starting point : \n",
    "\n",
    "average_branches = dt.average_branches() # this is one of the stuff other libs don't do \n",
    "average_branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attached-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy :  0.8203434610303831\n",
      "Testing accuracy :  0.7611940298507462\n"
     ]
    }
   ],
   "source": [
    "# looks like we have 7 branches in total. Maybe we can add a max_branches = 4 term \n",
    "dt = DecisionTree(max_branches = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "evaluate(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tired-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy :  0.8731836195508587\n",
      "Testing accuracy :  0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "# that seems to do a little bit better. Luckily there's another option as well. We can also use\n",
    "# the min_samples parameter. Basically if when we are creating a tree we realize that we are only dealing with a \n",
    "# few samples and making many, many trees to make all of them sorted perfectly - we are overfitting. \n",
    "# we can just reduce this by setting a min_samples parameter\n",
    "dt = DecisionTree(max_branches = 4, min_samples = 10)\n",
    "dt.fit(X_train, y_train)\n",
    "evaluate(dt, X_train, y_train, X_test, y_test) # this does slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "olive-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2,\n",
       "  1): {True: {(1,\n",
       "    3): {True: {(6, 23.45): {True: 0.0,\n",
       "      False: {(3, 8.0): {True: 0.0,\n",
       "        False: {(6, 15.5): {True: 1.0,\n",
       "          False: {(6, 8.05): {True: 0.0,\n",
       "            False: {(5, 2): {True: 0.0,\n",
       "              False: {(0, 265): {True: 1.0, False: 1.0}}}}}}}}}}}}, False: {(0,\n",
       "      304): {True: {(0, 855): {True: 1.0,\n",
       "        False: {(6, 151.55): {True: 1.0, False: 1.0}}}},\n",
       "      False: {(0, 298): {True: 0.0,\n",
       "        False: {(6, 30.0708): {True: 1.0,\n",
       "          False: {(6, 28.7125): {True: 0.0,\n",
       "            False: {(3, 29.0): {True: 1.0,\n",
       "              False: {(3, 24.0): {True: {(5, 2): {True: 1.0, False: 0.0}},\n",
       "                False: 1.0}}}}}}}}}}}}}}, False: {(6,\n",
       "    26.2875): {True: {(0,\n",
       "      391): {True: {(4, 4): {True: 0.0,\n",
       "        False: {(3, 55.0): {True: 0.0,\n",
       "          False: {(0, 742): {True: 0.0,\n",
       "            False: {(0, 725): {True: 1.0,\n",
       "              False: {(6, 26.55): {True: 1.0, False: 1.0}}}}}}}}}}, False: {(0,\n",
       "        184): {True: {(0, 263): {True: 0.0,\n",
       "          False: {(3, 1.0): {True: 1.0, False: 0.0}}}},\n",
       "        False: {(4, 1): {True: 0.0,\n",
       "          False: {(0, 103): {True: 0.0,\n",
       "            False: {(3, 54.0): {True: 0.0,\n",
       "              False: {(6, 56.4958): {True: 1.0,\n",
       "                False: {(0, 65): {True: 0.0,\n",
       "                  False: 1.0}}}}}}}}}}}}}}, False: {(5,\n",
       "      1): {True: {(3,\n",
       "        15.0): {True: {(7, (0.0, 1.0, 0.0)): {True: 0.0,\n",
       "          False: 0.0}}, False: {(3,\n",
       "          0.42): {True: {(0, 194): {True: 1.0, False: 0.0}},\n",
       "          False: 0.0}}}}, False: {(0,\n",
       "        583): {True: {(0, 745): {True: {(0, 750): {True: 0.0, False: 1.0}},\n",
       "          False: {(4,\n",
       "            1): {True: {(6, 16.1): {True: 0.0,\n",
       "              False: {(6, 7.925): {True: 1.0,\n",
       "                False: 0.0}}}}, False: 0.0}}}}, False: {(0,\n",
       "          570): {True: {(3, 32.0): {True: 1.0, False: 0.0}}, False: {(3,\n",
       "            45.0): {True: 0.0,\n",
       "            False: {(3,\n",
       "              42.0): {True: {(0,\n",
       "                289): {True: {(6, 13.0): {True: 1.0,\n",
       "                  False: {(3, 44.0): {True: 1.0, False: 0.0}}}},\n",
       "                False: 0.0}}, False: {(0,\n",
       "                38): {True: {(0,\n",
       "                  82): {True: {(0, 88): {True: 0.0,\n",
       "                    False: 1.0}}, False: 0.0}}, False: {(0,\n",
       "                  18): {True: {(6, 26.0): {True: 0.0,\n",
       "                    False: {(6, 13.0): {True: 1.0,\n",
       "                      False: {(0, 37): {True: 1.0,\n",
       "                        False: 0.0}}}}}}, False: 0.0}}}}}}}}}}}}}}}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you are curious, the way we build trees is through a lot recursion. We store the tree in a dictionary, which looks\n",
    "# really, really long and repetitive. \n",
    "\n",
    "tree = dt.return_tree()\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cultural-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we could do now is create another tree and implement that in our original dt class\n",
    "dt_new = DecisionTree(max_branches = 5, min_samples = 5)\n",
    "dt_new.fit(X_train, y_train)\n",
    "tree = dt_new.return_tree()\n",
    "dt.give_tree(tree) # insert the tree from dt_new and add it to dt\n",
    "assert dt.return_tree() == dt_new.return_tree() == tree # they all share the same tree now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adjustable-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68., 10.],\n",
       "       [17., 39.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEWCAYAAABLzQ1kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmpUlEQVR4nO3dd3yV5fnH8c+VRQIhBAKELSgIAiouRFCLA0e1goriaqlVqbO1Und/WhGpqziKtcWJ4oCiCI6iiKKiqCAORlRWQGYAmSFAxvX74zykAZKck5CEB/i+fT2vnGfd5z5H8j13rmccc3dERCR84vZ0B0REpHQKaBGRkFJAi4iElAJaRCSkFNAiIiGlgBYRCSkFtOw2M0sxszfNbL2Z/Wc32rnUzN6ryr7tCWb2XzPrv6f7IXs/BfR+xMwuMbPpZrbJzJYHQXJ8FTTdF8gEMtz9gso24u4vuftpVdCfHZhZTzNzMxu70/LDg+WTY2znr2Y2Mtp27n6mu4+oZHdFiimg9xNmdhPwKDCESJi2Av4J9K6C5g8AfnT3gipoq7qsAo4zs4wSy/oDP1bVE1iEfqekyugf037AzOoBg4Dr3P11d89193x3f9Pdbw62qWVmj5rZsmB61MxqBet6mtkSMxtoZjnB6PvyYN09wF1Av2BkfsXOI00zax2MVBOC+d+a2QIz22hmC83s0hLLp5TYr7uZTQtKJ9PMrHuJdZPN7F4z+zRo5z0za1jO27ANeAO4KNg/HugHvLTTe/WYmf1kZhvM7CszOyFYfgZwR4nX+W2JftxnZp8Cm4EDg2VXBuufNLPXSrT/gJlNMjOL9f+f7L8U0PuH44BkYGw529wJdAO6AIcDXYG/lFjfBKgHNAeuAJ4ws/rufjeRUfkod09192fK64iZ1QEeB85097pAd+CbUrZrALwdbJsBDAXe3mkEfAlwOdAYSAL+XN5zAy8Avwkenw7MApbttM00Iu9BA+Bl4D9mluzuE3Z6nYeX2OfXwACgLrBop/YGAocGHz4nEHnv+rvusSAxUEDvHzKA1VFKEJcCg9w9x91XAfcQCZ7t8oP1+e7+DrAJaF/J/hQBnc0sxd2Xu/vsUrY5C5jr7i+6e4G7vwJ8D/yqxDbPufuP7p4HjCYSrGVy98+ABmbWnkhQv1DKNiPdfU3wnH8HahH9dT7v7rODffJ3am8zkfdxKDASuMHdl0RpTwRQQO8v1gANt5cYytCMHUd/i4JlxW3sFPCbgdSKdsTdc4mUFq4GlpvZ22bWIYb+bO9T8xLzKyrRnxeB64GTKOUvCjP7s5llBWWVdUT+aiivdALwU3kr3f0LYAFgRD5IRGKigN4/TAW2An3K2WYZkYN927Vi1z//Y5UL1C4x36TkSnd/1917AU2JjIqfiqE/2/u0tJJ92u5F4FrgnWB0WywoQdwCXAjUd/d0YD2RYAUoqyxRbrnCzK4jMhJfFrQvEhMF9H7A3dcTOZD3hJn1MbPaZpZoZmea2YPBZq8AfzGzRsHBtruI/EleGd8AJ5pZq+AA5e3bV5hZppn1DmrRW4mUSopKaeMd4ODg1MAEM+sHdATeqmSfAHD3hcAviNTcd1YXKCByxkeCmd0FpJVYvxJoXZEzNczsYGAwcBmRUsctZtalcr2X/Y0Cej8R1FNvInLgbxWRP8uvJ3JmA0RCZDrwHTATmBEsq8xzTQRGBW19xY6hGhf0YxnwM5GwvKaUNtYAZxM5yLaGyMjzbHdfXZk+7dT2FHcv7a+Dd4EJRE69WwRsYcfyxfaLcNaY2YxozxOUlEYCD7j7t+4+l8iZIC9uP0NGpDymg8kiIuGkEbSISEgpoEVEQkoBLSISUgpoEZGQKu/ChT0q5YjrdfRSdrF22rA93QUJoeQEdvveJhXJnLyvh9XIvVQ0ghYRCanQjqBFRGpUCO8Uq4AWEQGIi9/TPdiFAlpEBCCEt+hWQIuIgEocIiKhpRG0iEhIaQQtIhJSGkGLiISUzuIQEQkplThEREJKJQ4RkZDSCFpEJKQU0CIiIRWvg4QiIuGkGrSISEipxCEiElIaQYuIhJRG0CIiIaURtIhISOlSbxGRkFKJQ0QkpFTiEBEJKY2gRURCSgEtIhJSOkgoIhJSIaxBh29MLyKyJ1hc7FO0pszSzWyMmX1vZllmdpyZNTCziWY2N/hZP1o7CmgREYiMoGOdonsMmODuHYDDgSzgNmCSu7cDJgXz5VJAi4gAZhbzFKWdesCJwDMA7r7N3dcBvYERwWYjgD7R+qSAFhGhYgFtZgPMbHqJaUCJptoAq4DnzOxrM3vazOoAme6+PNhmBZAZrU86SCgiAlhc7AcJ3X04MLyM1QnAkcAN7v6FmT3GTuUMd3cz82jPoxG0iAhVV+IAlgBL3P2LYH4MkcBeaWZNg+dqCuREa0gBLSJC1QW0u68AfjKz9sGiU4A5wHigf7CsPzAuWp9U4hARgVhGxhVxA/CSmSUBC4DLiQyIR5vZFcAi4MJojSigRUQAqjCf3f0b4OhSVp1SkXYU0CIiVPkIukoooEVEgLi48B2SU0CLiKARtIhIeIUvnxXQIiKgEbSISGgpoEVEQqoil3rXFAW0iAgaQYuIhJYCWkQkpBTQIiIhpYAWEQmr8OWzAlpEBHSpt4hIaKnEISISVuHLZ32jSjSZGXV54f7LmT3+bj596RbG/uMa2rZqXGPPf9mvjqVpo3oV3q9zu2ZMHjGQr8bcybTRd1ArKfJZfOEZRzFt9B18Oep2xg27loz0OqXu//db+jJr3N18Oep2unRosVuvYV/Q7egj9nQXyjXyhefJy8ur0D4LF8zn15f04+gunRnx3DM7rPv0k48556zTOfuMXjzzVOlfvbdt2zZuHngjZ5/Ri0svuoClS5dUuv9hUIVfeVVlFNBRjBo6gI+nz6XTOffQ49IHuesf48nMqBvTvvHxceXOx+LX53SrcEDHx8fx7OD+3HDfqxzV9z5Ov+ox8gsKiY+P46Gb+3LGgMfo2u9vzJq7lKv7/WKX/U8/viMHtWpE5973cP3gV3j8josq3G+JXUFBQbnzsXjpxRfYsqViAZ1WL51bb7+T/pdfscPywsJChtw3iH/+62nGjn+bCe+8xfx583bZf+xr/yEtLY23Jkzkst/8lkeHPlzhfodJGAO62kocZtYB6A00DxYtBca7e1Z1PWdV+8UxB5NfUMjTY6YUL5v549Lix0Nu7MNpPTriDg88PYEx783ghKPacfe1Z7F2Yx7tW2dy3b2v7DDf5bx7GfyH3px4dDuSEhP49+iPeea1TwEY+NtTueiXXSnyIt77dA4z5izmyI6teO6+/uRtzadn/7+zZWt+1H6felwHZs1dWtzXn9fnApCQYJhBnZQk1qzLpW5qCvN/Wr3L/mf/4jBefutLAL6cmU29uik0aZjGitUbKv9m7iOmffkF//rnMNLT6zNv3o907NiJIQ88jJkxa+Z3PHj/EPI2byYxKYmnnn2ehIREBg/6K3NmzyI+Pp4/33IbXY/txrixrzPp/ffYvHkzRUVF9O5z3g7zw54czv1D7mXe3LkUFBRwzXXXc9LJp1JYWMijQx/m0ymfEBdnnNf3QtydnJwcrry8P+np6Tzz/IsxvZaMjAwyMjL45OOPdlg+a+Z3tGx5AC1atgTgjF+exeQPJ3FQ27Y7bPfhBx9wzXXXA9DrtNO5/75BuHsoa7mxCGO/qyWgzexW4GLgVeDLYHEL4BUze9Xd76+O561qndo25es5i0td1+eULhzWvgVd+/2NhumpTBl5M1NmREYZXQ5pyVF9h7Bo2RpOOKrdDvO/O68H6zflcfxlD5GUmMAHz9/E+1O/p32bTM7ueRgn/uYh8rbkUz+tNms3bObqfr/g9kfGMqOUflzZ93iAHT5AANq1aow7jH/iOhrWT2XMu18xdMT7FBQU8ccho5g2+g5y87Yx/6dV3Pi3Ubu026xxOktWrC2eX7pyHc0apyugA99nzeH1cW/TqHFj+l92MV/P+IpDDz2MW/78Jx58+BE6H3oYmzZtolatZF4a+QJm8Nobb7JwwXyuvuoKxr/zLgBZWXMY8/p46qWnM27s6zvMP/7oULoe241Bg//Ghg0buPSiCzi2W3feGv8Gy5YuZfRrb5CQkMD6deuol57OyBHP8/RzI6hfv8Eu/X3iH4/RqVNnep4c27ct5axcSZOmTYrnG2dmMvO773bdLmclTZo0BSAhIYHUunVZt25tqX3YG+xP9+K4Aujk7jsM98xsKDAbKDWgzWwAMAAgoUVPEhp2qqbu7b7uXQ5k9ITpFBU5OT9v5JOv5nFUpwPYsGkL02ctYtGyNcXblpw/9bgOdG7XnHNPjdQ066Um07ZVI04+tj0vjPucvC2Rt2zths1R+7BzMG+XEB9P9yMO5PjLHmLzlm38999/YEbWYqbMmMdVfU+g28UPsHDJah659QJu/t1pPPD0u7v7duxXOh96GJlNIgHWvkMHli1bSt26dWnUsBGdDz0MgNTUVAC+nvEVF19yGQBtDjyIps2asSh7IQDdjutBvfT04nZLzk/9bAqTP/yAF557FoBtW7eyYvlyPp86lQv6XURCQuRXt+T+Zbnuhj/u9mveH+w3I2igCGhG5JtrS2oarCuVuw8HhgOkHHG9V1PfYjZn/vLiIK2I3LxtZc6bGTc98B/en7pjpadX90Mq18lSLM1Zx5QZ81mzLlLamDBlNkd0aMnGTVsAWLgkUtYYM3EGf778tF32X5azjhZN6hfPN89MZ1nOuirr394uMSmp+HFcXDyFBYWVaiclJaXMeXcY+ujjtG5zYOU6uRsaZ2ayYvmK4vmclSvJzMzcdbvGmaxYsZzMJk0oKChg08aNpKfX32W7vUUYA7q6DhLeCEwys/+a2fBgmgBMAvaaj/PJX/5IrcQEfndej+Jlnds1o8cRB/Hp1/Ppe9pRxMUZDeuncvxRbZk+KztqmxM/y2LABceTkBB569u2akzt5CQmff49v+ndjZTkRADqp9UGYGPuFlJr16pQvyd+NodObZuRkpxIfHwcJxzVlqwFK1i2aj0dDmxCw/qR0d0p3Trww8IVu+z/9kczueTsrgB0PbQ1GzblqbwRRevWbVi1ehWzZkZKAbm5mygoKODII4/mnbffBCA7eyErli+PKXS79ziel18aiXtknJKVNQeAbt27M2b0qOIDievXrQOgdp065ObmVslr6dT5UBYvzmbJkp/I37aNCe+8zS9OOnmX7XqedDLjx40FYOJ779L12G6hDLlYmcU+1ZRqGUG7+wQzOxjoyo4HCae5e+WGG3tIv4FP8dCfz2fgb09ly7YCFi1bw80Pv8anX8/n2MPa8OWo23GHOx99g5VrNnJw6ybltvfc2M84oFkDpr58G2aweu0mLrxpOBM/y+Lw9i349KVb2JZfyLtTZnP3sDcZ+eYX/OPOi0o9SFhWDXrdxjweH/kBU0begrvz7pTZTJgyG4Ahw//LxKdvJL+gkMXLf2bA3SN3aWvClNmcfnwnZo+/m81b8vn9X0dW2fu5r0pMSuLBhx/h/iGD2bplC7WSkxn+9HP0u/gSBg/6K+f3+RXx8fEMuu9vJJUYgZdlwNXX8uD9Q+h77jkUFRXRvEULhv3z35x3/gUsys7mgnPPISEhgfP6XsjFl17G+RdcyLW/v5JGjRrvcpCwrBr06lWruLjf+eRu2kRcXBwjXxzB2PHvkJqayu133sU1A66kqKiQPueeT9u27XZp69zz+3LnbTdz9hm9SKtXjwcffqTK3s89IYwfLrb9EzpswlDikPBZO23Ynu6ChFBywu5fZtL+1ndjzpwfHji9RtJcVxKKiFCzpYtYKaBFRIC4/eg0OxGRvYpG0CIiIRXGg4QKaBERNIIWEQmtqrxhv5llAxuBQqDA3Y82swbAKKA1kA1c6O5ry2oDdDc7ERGgWi5UOcndu7j70cH8bcAkd29H5KK926I1oIAWEaFGbjfaGxgRPB4B9Im2gwJaRISKjaDNbICZTS8xDdipOQfeM7OvSqzLdPflweMVwK43ONmJatAiIlTsLI6SN3Yrw/HuvtTMGgMTzez7nfZ3M4t65aJG0CIiVG0N2t2XBj9zgLFE7ku00syaRp7LmgI50dpRQIuIELmSMNapPGZWx8zqbn8MnAbMAsYD/YPN+gPjovVJJQ4REar0QpVMYGzQXgLwcnCHz2nAaDO7gsi98i+M1pACWkSEqrtQxd0XAIeXsnwNENv3jgUU0CIi6FJvEZHQCmE+K6BFREC3GxURCS2VOEREQkoBLSISUiHMZwW0iAhoBC0iElohzGcFtIgI6CwOEZHQigvhEFoBLSKCShwiIqGlg4QiIiEVwhK0AlpEBHSQUEQktAwFtIhIKIVwAK2AFhEBHSQUEQmtEOazAlpEBHShiohIaOksDhGRkArhAFoBLSIC4SxxxMWykZn1MLM6wePLzGyomR1QvV0TEak5VoGppsQU0MCTwGYzOxwYCMwHXqi2XomI1DAzi3mqKbEGdIG7O9AbGObuTwB1q69bIiI1K85in2pKrDXojWZ2O3AZcKKZxQGJ1dctEZGaFcazOGIdQfcDtgJXuPsKoAXwULX1SkSkhoWxxBHTCDoI5aEl5hejGrSI7ENCOIAuP6DNbCPgpa0C3N3TqqVXIiI1rKpHxmYWD0wHlrr72WbWBngVyAC+An7t7tvKa6PcEoe713X3tFKmugpnEdmXVMNpdn8EskrMPwA84u5tgbXAFdEaiLUGjZkdb2aXB48bBp8GIiL7hPg4i3mKxsxaAGcBTwfzBpwMjAk2GQH0idZOrBeq3A3cCtweLEoCRsayr4jI3qAiBwnNbICZTS8xDdipuUeBW4CiYD4DWOfuBcH8EqB5tD7FeprducARwAwAd19mZjoPWkT2GRUpQbv7cGB46e3Y2UCOu39lZj13p0+xBvQ2d3cz86ADdXbnSUVEwqYK78XRAzjHzH4JJANpwGNAupklBKPoFsDSqH2K8QlHm9m/gye4CngfeKpSXRcRCSGz2KfyuPvt7t7C3VsDFwEfuPulwIdA32Cz/sC4aH2K9Tzoh82sF7ABOBi4y90nxrJvZWW9/3B1Ni97qYFvZkXfSPY7T5x7yG63UQMXoNwKvGpmg4GvgWei7VCR243OBFKInBc9s1LdExEJqfhqCGh3nwxMDh4vALpWZP9Yz+K4EvgSOI/IEP1zM/tdRZ5IRCTM9uabJd0MHOHuawDMLAP4DHi2ujomIlKT9rpLvUtYA2wsMb8xWCYisk+oyZsgxSravThuCh7OA74ws3FEatC9ge+quW8iIjVmbxxBb78YZX4wbRf19BARkb1JCAfQ5Qe0u99TUx0REdmTEkKY0DHVoM2sEZHryjsRuTIGAHc/uZr6JSJSo0KYzzFfSfgS8D3QBrgHyAamVVOfRERqXJxZzFON9SnG7TLc/Rkg390/cvffEbl1nojIPqGqLvWuSrGeZpcf/FxuZmcBy4AG1dMlEZGatzeexbHdYDOrBwwE/kHk7kw3VlenRERqWiw34q9psd4s6a3g4XrgJAAzu7Ga+iQiUuNCmM+xf+VVKW6KvomIyN7BKvBfTanI3ex2FsLPGxGRygnjCHp3AtqrrBciInvYXhfQZraR0oPYiNwbWkRkn7DX3SzJ3fXFsCKyX4jfnSNy1WR3ShwiIvuMmrxCMFYKaBER9sIatIjI/iKEA2gFtIgIQFwIzxxWQIuIoBG0iEhoJYSwCK2AFhFBI2gRkdDSaXYiIiEVwnxWQIuIwO7d2rO6KKBFRFCJQ0QktMIY0GEc1YuI1DirwFRuO2bJZvalmX1rZrPN7J5geRsz+8LM5pnZKDNLitYnBbSICFX6rd5bgZPd/XCgC3CGmXUDHgAecfe2wFrgimgNKaBFRIjcDzrWqTwesSmYTQwmB04GxgTLRwB9ovVJAS0iQiQMY53MbICZTS8xDSjZlpnFm9k3QA4wEZgPrHP3gmCTJUDzaH3SQUIRESp2kNDdhwPDy1lfCHQxs3RgLNChMn1SQIuIUD1feeXu68zsQ+A4IN3MEoJRdAtgabT9VeIQEaFiJY7ymFmjYOSMmaUAvYAs4EOgb7BZf2BctD5pBC0iQpWOoJsCI8wsnkiej3b3t8xsDvCqmQ0GvgaeidaQAlpEhOjnN8fK3b8Djihl+QKga0XaUkCLiADxIbySUAEtIoLuZiciElqm7yQUEQknjaBFREJK3+otIhJSGkGLiIRUGO8HrYAWEQHiwpfPCmgREdBZHCIioRXCCocCeme9T+nGuEmf7+lulOn1USP5Ze/zSU5OiXmfxdkLGXrfXcz7MYv+v7+BCy7pD8BPi7IZctctxdutWLqEX191Lef1u2yH/d2dJx95gC+nTiE5OZmBf7mXdu0PqZoXtJdKqxXP+YdlckB6Cnn5hWzcWsiYmSvJ2bStRp6/W6t6ZOXksn5LQfSNAwfUT+aSLk0jMwbvZK3m2+UbAeh5UH16tE7HMD7NXsuH89eW2sYFh2XSKTOVbYVFvPjVcn5av2W3X0tYaAS9nyssKCA+IaHM+Vi8MeolTjn9rAoFdFpaGtf86VY++/jDHZa3PKA1T44YHelLYSGX9u5FjxNP3mX/aVOnsHTJYp4b/Sbfz57JPx4azONPv1Shfu9rrurWgi8Wree5acsAaJ5Wi7q14snZFGVHIrXOIi97PhbHtqrHsg1bKxTQyzZs5YHJCylySKuVwB2ntGHmio1kptaiR+t0HpycTWGRc133VsxasYlVufk77N8psw6N6iTx14nzaV0/mYu6NOGhj7Ir1vEQUw16L/LtjGmMfOZfpNVLJ3vBPNp16Mitdw/BzPhhziyefPRBtmzJIzExkQcef4qEhAQef2gwc7+fQ3x8PAP+8Ge6HNWV994ex6cfTSJv82aKioo47azeO8wP/vswnhh6P9kL5lFYUMBlV1xD9xNPorCwkGf++SjTP/+UuLg4zjznPNydNatzuOX6K0lLT+ehYVFvhgVAeoMM0htk8OVnn5S5zTfTv6Bp85ZkNm22y7qpn3zIqWf8CjPjkM6HkbtpI2tWryKjYaNKv797s4Mb1qaoCKZkrytetnTD1uLH53ZuTMfMOrjDhB9WM2PpRto1rM3ZhzRic34hmXWTeOXrFTvM3ztxAX06N6Zdw9okxBkfL1hb3H6vdhkc0zINB+as3MTitVs4oH4Kvz26GfmFzsMfZZMfQ8LnF/5vm8R4w4PZJnWTyP55S/H6uas3c3izurw/9+cd9j+saV2++Gk9ANlrt5CSGEdarQQ2bI39QyLMdBbHXmbej98z/KXXyWjYiJt+35/Z331N+46HMuSuW7hj0IO079iZ3NxN1KpVi7GjX8LM+PfI11icvZA7/nQ1z746PtLOD1k8+eIY0tLq8d7b43aYf/Zfj9PlqK4MvHMQmzZu4A9XXsqRxxzLxP++xcrly3hyxGjiExLYsGE9aWn1eP3VkTw47Gnqpdffpb8jnnqCgzt04rgTelb4tU5+fwI9e51R6rrVq3JolJlZPN+wUSZrVuXstwHdLK0Wi9fllbquS7O6NK9XiyGTFpJaK55berZh3urIti3Tk7lv0gLWbM6nXcPaO8z3aJ1OXn4hD07OJiHOuOnEA8jKySWzbhKHNU3loY+yyS90aifGsTm/iBMPzGPsrBwWr9u1xHB863Rgxw+Q7VrXT+ayI5vRoHYiI6Yvo8hh2cat/KpTI+okxbOtsIhOTeqweO2u7dZLSWBd3v9G1evyCkhP2XcCOnzxvAcC2swud/fnylg3ABgAcN/fh3FJ/6hfelut2nfsTKPGkWA68OD2rFy+jDqpdWmQ0Yj2HTsDUKdOKgCzv/ua3n0vBqBV6zY0btKUJT8tAuCIY7qRllavuN2S8zO+nMrnn0xmzCsvALBt2zZyVq7g6+mfc1afC4pLICX3L0v/q66r1OvMz8/n8ykf8btr/lip/eV/DspI4aslG3Bg49ZC5q3ezAH1k9lSUMSitXms2fy/gCs5f0jjOjSrV4sjmqUBkJwYR6PUJDo0qsPUxeuLR7eb84ui9qG0YN4ue+0WBk9aQGbdJH5zZDNmr9zEyo3bmPjjGq7v3pJthc7SdVsrXHLZF2gEHXEPUGpAl/yer+w1W/b4P5HExMTix3FxcRQWFlaqneSUlDLn3Z3/GzKUlge0rlTbVWHa1Cm0PbgD9RtklLq+YaPGrFq5snh+9aqVZDRqXFPdC53lG7dyRPO0Cu+3tbCo3Pn/fLuSrJzcHZZ1bFyn4h2MwcqN29haWBT8NbCFqYvWM3VRpHxxTsdGrM3bdVS8Pq+A9JREIPIXQXpKAutK2W5vFb54rqavvDKz78qYZgKZURsIsRatWvPzmlX8MGcWAJtzcyksKKDz4UfywXvvALBkcTarVqygRavWUds76tjujBvzMh4UBOf9kAXAkcd04503xlBYEPkF2LAh8suTUrs2eZtzS2+skiZP/C89e51Z5vpux/fk/Qlv4u5kzfqO2nVS99vyBsAPqzaTEGf0CEoJECl7HJSRwrw1eRzZPA0DUpPiaduwNovWll4OKSkrJ5cT2tQvPlDVODWJpHjj+5xcjmtVj8T4yIraiZFf2a0FRdRKqNivb0btxOL2G6QkkJmaVDyCT02KB6B+SgKHN6vL9CXrd9n/u+WbOLZl5C+51vWTycsv2mfKG0AkoWOdakh1jaAzgdOBnc/VMeCzanrOGpGYmMgdgx7kn4/cz9atW6lVqxb3PzacX53Xj8cfGszvLzuf+Ph4Bv5lEElJSVHbu/TyAfzr0Qe5+td9KfIimjRtzr0PD+PMX53H0sWLuPo3kTLHmeecR+++F/PL3udz503X0qBho10OEpZVg/55zWpu+N3FbM7NxeLieGPUSIa/PJY6dVLZkreZGdM+54+3/t8O+7w1NnJ2x9nnXkjX7icwbeoULr/gbGolJzPwzkG79ybuA4Z/sYS+h2bSq10GBUXOms35jPluBfPX5HFggxTuOKUN7jB21ko2bC0ks2757X2WvY6M2oncdlIbzGDT1kL+/fkS5uTk0jw9mVt7tqGwyJm9chPj56zi88XrubhLk1IPEpZVgz4oI4XTDm5JYZFTBIz6dgW52yJ/FV51bAvqJMVT6M7ob1eQF5RSSrY1e+UmOjWpw197HcS2wiJGzlheFW9laISxxGHbR25V2qjZM8Bz7j6llHUvu/sl0doIQ4lDwuehjxfu6S5ICD1x7iG7na7TFqyPOXOOObBejaR5tYyg3b3Mo3uxhLOISI0L3wBap9mJiICuJBQRCa0QlqAV0CIiEMoKhwJaRATAQjiEVkCLiKASh4hIaIUwnxXQIiJAKBNaAS0iQjhPs6uWe3GIiOxtzGKfym/HWprZh2Y2x8xmm9kfg+UNzGyimc0Nfu56z+CdKKBFRKi6gAYKgIHu3hHoBlxnZh2B24BJ7t4OmBTMl0sBLSJCpMQR63/lcffl7j4jeLwRyAKaA72BEcFmI4A+0fqkgBYRoWIjaDMbYGbTS0wDSm/TWgNHAF8Ame6+/RaAK4jh1ss6SCgiQsVO4ij55SJltmeWCrwG3OjuG0peCOPubmZR756nEbSICFTpDfvNLJFIOL/k7q8Hi1eaWdNgfVMgJ1o7CmgRESI37I91Ko9FhsrPAFnuPrTEqvFA/+Bxf2BctD6pxCEiQpVep9ID+DUw08y+CZbdAdwPjDazK4BFwIXRGlJAi4hAlSV08E1SZbV2SkXaUkCLiBDOKwkV0CIi6G52IiKhFcJ8VkCLiIBu2C8iElohzGcFtIgIqMQhIhJeIUxoBbSICDrNTkQktFSDFhEJqTgFtIhIWIUvoRXQIiKoxCEiElohzGcFtIgIaAQtIhJautRbRCSkwhfPCmgREUAlDhGR0NKVhCIiYRW+fFZAi4hAKPNZAS0iAhAXwiK0AlpEhHAeJIzb0x0QEZHSaQQtIkI4R9AKaBERdJqdiEhoaQQtIhJSCmgRkZBSiUNEJKTCOILWaXYiIkSuJIx1itqW2bNmlmNms0osa2BmE81sbvCzfrR2FNAiIlC1CQ3PA2fstOw2YJK7twMmBfPlUkCLiBC51DvWKRp3/xj4eafFvYERweMRQJ9o7Zi7V/BlSE0zswHuPnxP90PCRf8u9hwzGwAMKLFo+M7/L8ysNfCWu3cO5te5e3rw2IC12+fLfB4FdPiZ2XR3P3pP90PCRf8uwq28gA7m17p7uXVolThERGrGSjNrChD8zIm2gwJaRKRmjAf6B4/7A+Oi7aCA3juoziil0b+LkDKzV4CpQHszW2JmVwD3A73MbC5wajBffjuqQYuIhJNG0CIiIaWAFhEJKQV0yJnZGWb2g5nNM7OoVx7Jvq+0y4hl36SADjEziweeAM4EOgIXm1nHPdsrCYHn2fUyYtkHKaDDrSswz90XuPs24FUil4vKfqyMy4hlH6SADrfmwE8l5pcEy0RkP6CAFhEJKQV0uC0FWpaYbxEsE5H9gAI63KYB7cysjZklARcRuVxURPYDCugQc/cC4HrgXSALGO3us/dsr2RPK+MyYtkH6VJvEZGQ0ghaRCSkFNAiIiGlgBYRCSkFtIhISCmgRURCSgEt1cLMCs3sGzObZWb/MbPau9HW82bWN3j8dHk3jDKznmbWvRLPkW1mDSvbR5HqoICW6pLn7l2CbzTeBlxdcqWZJVSmUXe/0t3nlLNJT6DCAS0SRgpoqQmfAG2D0e0nZjYemGNm8Wb2kJlNM7PvzOz3ABYxLLgP9vtA4+0NmdlkMzs6eHyGmc0ws2/NbFLwNfdXA38KRu8nmFkjM3steI5pZtYj2DfDzN4zs9lm9jRgNfyeiERVqVGMSKyCkfKZwIRg0ZFAZ3dfaGYDgPXufoyZ1QI+NbP3gCOA9kTugZ0JzAGe3andRsBTwIlBWw3c/Wcz+xewyd0fDrZ7GXjE3aeYWSsiV2UeAtwNTHH3QWZ2FqCr8SR0FNBSXVLM7Jvg8SfAM0RKD1+6+8Jg+WnAYdvry0A9oB1wIvCKuxcCy8zsg1La7wZ8vL0tdy/r/sinAh3NigfIaWaWGjzHecG+b5vZ2sq9TJHqo4CW6pLn7l1KLghCMrfkIuAGd393p+1+WYX9iAO6ufuWUvoiEmqqQcue9C5wjZklApjZwWZWB/gY6BfUqJsCJ5Wy7+fAiWbWJti3QbB8I1C3xHbvATdsnzGzLsHDj4FLgmVnAvWr6kWJVBUFtOxJTxOpL88IvgD130T+qhsLzA3WvUDkzm07cPdVwADgdTP7FhgVrHoTOHf7QULgD8DRwUHIOfzvbJJ7iAT8bCKljsXV9BpFKk13sxMRCSmNoEVEQkoBLSISUgpoEZGQUkCLiISUAlpEJKQU0CIiIaWAFhEJqf8HTkzi7LR00yoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# of course if you retrain the model, this tree will be lost. \n",
    "# but for now you get to keep it and use it in the predict() method. This will be important for things like Random Forests\n",
    "# where you may make 500 such decision trees, get the best one, and use it. \n",
    "\n",
    "# lastly we'll want to make a confusion matrix (just something I like to do)\n",
    "from sealion.utils import confusion_matrix\n",
    "y_pred = dt.predict(X_test)\n",
    "confusion_matrix(y_pred, y_test) #always this order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It looks like we make more false positives than false negatives. This is good as then we are telling somebody more often\n",
    "#that they will die (0) when they survive (1) instead of the opposite. Of course neither is optimal.\n",
    "\n",
    "# well that looks like all for today's tutorial. We hope you enjoyed it, thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
